The [[http://archive.ics.uci.edu/ml/datasets/Wine|Wine Dataset]] is a rather simple dataset. It comes as a CSV file and is made up of 178 lines with a class label and 13 properties.

In this post I want to show you how to use [[http://www.csie.ntu.edu.tw/~cjlin/libsvm/|libsvm]] with [[http://www.python.org|Python]]. [[http://www.python.org|Python]] comes with a built-in csv reader, so it's easy to read the data. Always make sure not to include any class labels in your feature vector, because this would make prediction trivial and useless. 

First we'll perform a 10-fold cross validation on the raw data. This shows that the default RBF and the sigmoid kernel don't work on raw data; both perform only slightly better than random guessing. The linear and polynomial kernel function are better suited for raw data with both having around 95% cross-validation accuracy. 

I've played with the dataset [[wiki:pca_lda_with_gnu_octave|before]] and we saw that normalization sometimes matters. Here is how to do a min-max or [[http://en.wikipedia.org/wiki/Standard_score|z-score]] normalization with NumPy:

<code Python>
def normalize(X, low=0, high=1, minX=None, maxX=None):
	X = np.asanyarray(X)
	if minX is None:
		minX = np.min(X)
	if maxX is None:
		maxX = np.max(X)
	# Normalize to [0...1].	
	X = X - minX
	X = X / (maxX - minX)
	# Scale to [low...high].
	X = X * (high-low)
	X = X + low
	return X
	
def zscore(X):
	X = np.asanyarray(X)
	return (X-X.mean())/X.std()
</code>

On normalized data the RBF performs better with 98% accuracy and the sigmoid kernel has 97%. To finally learn a model you have to switch the cross validation off and train the model on your data. With //svm_predict// you would generate predictions for your input data. 

You probably ask yourself now how to normalize unseen input data. If you know the range your inputs can take, just do a min-max normalization with the given min and max. If your data is drawn from a [[http://en.wikipedia.org/wiki/Stationary_process|stationary process]] you can assume, that mean and variance doesn't change over time. So you could do a [[http://en.wikipedia.org/wiki/Standard_score|z-score]] normalization on the new data with the mean and standard deviation from your training data. Note that in the wine example all features were measured on a different scale, so you have to normalize each feature with its mean and standard deviation separately. 

Here's the script for you to play around with (download [[http://www.bytefish.de/files/python/libsvm_experiment2.py|files/python/libsvm_experiment2.py]]):
<code Python>
from svmutil import *
import numpy as np
import random
import csv

def normalize(X, low=0, high=1):
	X = np.asanyarray(X)
	minX = np.min(X)
	maxX = np.max(X)
	# Normalize to [0...1].	
	X = X - minX
	X = X / (maxX - minX)
	# Scale to [low...high].
	X = X * (high-low)
	X = X + low
	return X

def zscore(X):
	X = np.asanyarray(X)
	mean = X.mean()
	std = X.std() 
	X = (X-mean)/std
	return X, mean, std

reader = csv.reader(open('wine.data', 'rb'), delimiter=',')
classes = []
data = []
for row in reader:
	classes.append(int(row[0]))
	data.append([float(num) for num in row[1:]])

data = np.asarray(data)
classes = np.asarray(classes)

# normalize data
means = np.zeros((1,data.shape[1]))
stds = np.zeros((1,data.shape[1]))
for i in xrange(data.shape[1]):
	data[:,i],means[:,i],stds[:,i] = zscore(data[:,i])

# shuffle data
idx = np.argsort([random.random() for i in xrange(len(classes))])
classes = classes[idx]
data = data[idx,:]

# turn into python lists again
classes = classes.tolist()
data = data.tolist()

# formulate as libsvm problem
problem = svm_problem(classes, data)

param=svm_parameter("-q")

# 10-fold cross validation
param.cross_validation=1
param.nr_fold=10

# kernel_type : set type of kernel function (default 2)
#   0 -- linear: u'*v
#   1 -- polynomial: (gamma*u'*v + coef0)^degree
#   2 -- radial basis function: exp(-gamma*|u-v|^2)
#   3 -- sigmoid: tanh(gamma*u'*v + coef0)

#param.kernel_type=LINEAR # 95% (raw), 96% (zscore)
#param.kernel_type=POLY # 96% (raw), 97% (zscore)
param.kernel_type=RBF # 43% (raw), 98% (zscore)
#param.kernel_type=SIGMOID # 39% (raw), 98% (zscore)

# perform validation
accuracy = svm_train(problem,param)
print accuracy

# disable cv
param.cross_validation = 0

# training with 80% data
trainIdx = int(0.8*len(classes))
problem = svm_problem(classes[0:trainIdx], data[0:trainIdx])

# build svm_model
model = svm_train(problem,param)

# test with 20% data
# if data was not normalized you would do:
# data = (data-means)/stds
p_lbl, p_acc, p_prob = svm_predict(classes[trainIdx:], data[trainIdx:], model)
print p_acc

# perform simple grid search 
#results = []
#for c in range(-3,3):
#	for g in range(-3,3):
#		param.C, param.gamma = 2**c, 2**g
#		acc = svm_train(problem,param)
#		results.append([param.C, param.gamma, acc])

#bestIdx = np.argmax(np.array(results)[:,2])
#print results[bestIdx]
</code>
